globalprotect -> connect
and ur in

python3 run_experiment.py --nbr_clients 100 --nbr_rounds 200 --n_data_train 400 --n_data_val 100 --seed 1 --batch_size 8 --nbr_local_epochs 3 --lr 3e-5 --nbr_classes 10 --nbr_channels 3 --stopping_rounds 10 --nbr_neighbors_sampled 5 --prior_update_rule softmax --similarity_metric inverse_training_loss --tau 30 --experiment_name replication_DACvar_1


ideer: 
meta-neuralt n√§tverk - similarity metrics som input, actual similarity som output
kanske KL divergence som label


python3 run_experiment.py --nbr_clients 100 --nbr_rounds 270 --n_data_train 400 --n_data_val 100 --seed 1 --batch_size 8 --nbr_local_epochs 3 --lr 1e-4 --nbr_classes 10 --nbr_channels 3 --stopping_rounds 100 --nbr_neighbors_sampled 5 --similarity_metric inverse_training_loss --client_information_exchange PANM --T1 80 --NAEM_frequency 2 --experiment_name PANM_f_2_lr_1e-4


run_experiment.py --nbr_clients 20 --nbr_rounds 40 --n_data_train 400 --n_data_val 100 --seed 66 --batch_size 8 --nbr_local_epochs 3 --lr 3e-5 --nbr_classes 10 --nbr_channels 3 --stopping_rounds 10 --nbr_neighbors_sampled 3 --prior_update_rule softmax --similarity_metric some_dilusion --experiment_name some_dilusion_20_clients_3_dil_after_20_rounds


Why does cosine crash in our experiments?
Maybe because cosine is a weak similarity metric for label shift, which was not tested in the paper
They only tested label swapping and covariate shift.
In our case, we could have that DAC works in the beginning because all networks in a cluster learn the same 
general features. Then, the learning becomes too specialized, because each client is trying to learn more specific 
features of its own data, leaving no similarity in its gradient with its neighbors.
Then, some clients choose the wrong cluser which is very detrimental, and this spreads to other clients in the network

To prove this, we need to show that 'cluster death' is possible, and that that is what happens in our case
Also, we need to show that cosine similarity is effective in the way they have implemented it in the paper
To rule out errors in our code


mar 18:
Rerun all_data test with lower lr, or maybe not. Performance is similar to oracle, but curves look shaky and like lr is too high



# new algo
uninformed merging might not always be bad for accuracy, but it is bad for similarity signal strength

