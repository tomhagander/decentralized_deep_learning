{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/pacs-train\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://activeloop/pacs-train loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/pacs-val\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://activeloop/pacs-val loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/pacs-test\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://activeloop/pacs-test loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "import deeplake\n",
    "\n",
    "ds_train = deeplake.load(\"hub://activeloop/pacs-train\")\n",
    "ds_val = deeplake.load(\"hub://activeloop/pacs-val\")\n",
    "ds_test = deeplake.load(\"hub://activeloop/pacs-test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.initialization_utils import load_pacs, load_pickle_files\n",
    "\n",
    "filenames = ['photo_train.pkl', 'photo_val.pkl', 'photo_test.pkl', 'art_train.pkl', 'art_val.pkl', \n",
    "                    'art_test.pkl', 'cartoon_train.pkl', 'cartoon_val.pkl', 'cartoon_test.pkl', 'sketch_train.pkl', 'sketch_val.pkl', 'sketch_test.pkl']\n",
    "photo_train, photo_val, photo_test, art_train, art_val, art_test, cartoon_train, cartoon_val, cartoon_test, sketch_train, sketch_val, sketch_test = load_pickle_files('./PACS/', filenames)\n",
    "\n",
    "\n",
    "photo_train_indices = photo_train.indices\n",
    "photo_val_indices = photo_val.indices\n",
    "photo_test_indices = photo_test.indices\n",
    "art_train_indices = art_train.indices\n",
    "art_val_indices = art_val.indices\n",
    "art_test_indices = art_test.indices\n",
    "cartoon_train_indices = cartoon_train.indices\n",
    "cartoon_val_indices = cartoon_val.indices\n",
    "cartoon_test_indices = cartoon_test.indices\n",
    "sketch_train_indices = sketch_train.indices\n",
    "sketch_val_indices = sketch_val.indices\n",
    "sketch_test_indices = sketch_test.indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "path = '/home/master24/decentralized_deep_learning/Homework3-PACS/PACS/'\n",
    "DIR_PHOTO = path+'photo'\n",
    "DIR_ART = path+'art_painting'\n",
    "DIR_CARTOON = path+'cartoon'\n",
    "DIR_SKETCH = path+'sketch'\n",
    "means, stds = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n",
    "transf = transforms.Compose([ \n",
    "                            #transforms.Resize((224,224)),  # Crops a central square patch of the image 224 because torchvision's AlexNet needs a 224x224 input!\n",
    "                            transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
    "                            transforms.Normalize(means,stds) # Normalizes tensor with mean and standard deviation\n",
    "                            ])\n",
    "photo_dataset = torchvision.datasets.ImageFolder(DIR_PHOTO, transform=transf)\n",
    "art_dataset = torchvision.datasets.ImageFolder(DIR_ART, transform=transf)\n",
    "cartoon_dataset = torchvision.datasets.ImageFolder(DIR_CARTOON, transform=transf)\n",
    "sketch_dataset = torchvision.datasets.ImageFolder(DIR_SKETCH, transform=transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = torch.utils.data.Subset(sketch_dataset, sketch_train_indices)\n",
    "# save subset as a pickle file to PACS folder, with name photo_train.pkl\n",
    "import pickle\n",
    "with open('PACS/sketch_train.pkl', 'wb') as f:\n",
    "    pickle.dump(subset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[956,\n",
       " 1146,\n",
       " 581,\n",
       " 1262,\n",
       " 763,\n",
       " 1476,\n",
       " 451,\n",
       " 228,\n",
       " 416,\n",
       " 813,\n",
       " 6,\n",
       " 444,\n",
       " 435,\n",
       " 1411,\n",
       " 83,\n",
       " 819,\n",
       " 1312,\n",
       " 183,\n",
       " 1478,\n",
       " 10,\n",
       " 817,\n",
       " 632,\n",
       " 1391,\n",
       " 1104,\n",
       " 1499,\n",
       " 1080,\n",
       " 1550,\n",
       " 413,\n",
       " 414,\n",
       " 770,\n",
       " 1660,\n",
       " 1441,\n",
       " 1269,\n",
       " 1185,\n",
       " 895,\n",
       " 116,\n",
       " 1303,\n",
       " 1664,\n",
       " 1101,\n",
       " 289,\n",
       " 543,\n",
       " 1653,\n",
       " 1606,\n",
       " 944,\n",
       " 560,\n",
       " 833,\n",
       " 985,\n",
       " 54,\n",
       " 1287,\n",
       " 197,\n",
       " 1495,\n",
       " 1456,\n",
       " 1256,\n",
       " 1520,\n",
       " 923,\n",
       " 1492,\n",
       " 1611,\n",
       " 1173,\n",
       " 160,\n",
       " 459,\n",
       " 490,\n",
       " 841,\n",
       " 830,\n",
       " 281,\n",
       " 952,\n",
       " 818,\n",
       " 810,\n",
       " 750,\n",
       " 400,\n",
       " 1353,\n",
       " 1197,\n",
       " 559,\n",
       " 1236,\n",
       " 801,\n",
       " 349,\n",
       " 1027,\n",
       " 815,\n",
       " 1400,\n",
       " 982,\n",
       " 954,\n",
       " 1231,\n",
       " 1615,\n",
       " 1180,\n",
       " 1261,\n",
       " 1021,\n",
       " 1594,\n",
       " 645,\n",
       " 1528,\n",
       " 1398,\n",
       " 273,\n",
       " 1453,\n",
       " 1657,\n",
       " 1358,\n",
       " 27,\n",
       " 1663,\n",
       " 1512,\n",
       " 30,\n",
       " 1432,\n",
       " 920,\n",
       " 1128,\n",
       " 655,\n",
       " 513,\n",
       " 1202,\n",
       " 213,\n",
       " 894,\n",
       " 1352,\n",
       " 1412,\n",
       " 333,\n",
       " 1067,\n",
       " 1314,\n",
       " 1186,\n",
       " 253,\n",
       " 574,\n",
       " 605,\n",
       " 1493,\n",
       " 1362,\n",
       " 644,\n",
       " 404,\n",
       " 1388,\n",
       " 151,\n",
       " 1648,\n",
       " 361,\n",
       " 1582,\n",
       " 622,\n",
       " 878,\n",
       " 1521,\n",
       " 1142,\n",
       " 550,\n",
       " 1049,\n",
       " 1364,\n",
       " 206,\n",
       " 1181,\n",
       " 98,\n",
       " 385,\n",
       " 57,\n",
       " 564,\n",
       " 961,\n",
       " 1010,\n",
       " 203,\n",
       " 509,\n",
       " 299,\n",
       " 672,\n",
       " 243,\n",
       " 492,\n",
       " 480,\n",
       " 521,\n",
       " 937,\n",
       " 970,\n",
       " 1337,\n",
       " 1252,\n",
       " 1295,\n",
       " 1031,\n",
       " 1127,\n",
       " 567,\n",
       " 829,\n",
       " 616,\n",
       " 454,\n",
       " 1381,\n",
       " 965,\n",
       " 29,\n",
       " 412,\n",
       " 204,\n",
       " 1033,\n",
       " 1265,\n",
       " 612,\n",
       " 1339,\n",
       " 617,\n",
       " 973,\n",
       " 367,\n",
       " 535,\n",
       " 498,\n",
       " 548,\n",
       " 1108,\n",
       " 270,\n",
       " 984,\n",
       " 1007,\n",
       " 1267,\n",
       " 1174,\n",
       " 121,\n",
       " 766,\n",
       " 1502,\n",
       " 553,\n",
       " 1360,\n",
       " 1545,\n",
       " 1281,\n",
       " 235,\n",
       " 503,\n",
       " 1328,\n",
       " 598,\n",
       " 421,\n",
       " 201,\n",
       " 1230,\n",
       " 369,\n",
       " 70,\n",
       " 1346,\n",
       " 1164,\n",
       " 233,\n",
       " 58,\n",
       " 358,\n",
       " 755,\n",
       " 988,\n",
       " 621,\n",
       " 1618,\n",
       " 1525,\n",
       " 836,\n",
       " 1061,\n",
       " 439,\n",
       " 613,\n",
       " 35,\n",
       " 1001,\n",
       " 207,\n",
       " 1598,\n",
       " 1273,\n",
       " 745,\n",
       " 104,\n",
       " 851,\n",
       " 580,\n",
       " 1539,\n",
       " 828,\n",
       " 1373,\n",
       " 130,\n",
       " 1005,\n",
       " 1107,\n",
       " 1274,\n",
       " 376,\n",
       " 133,\n",
       " 1235,\n",
       " 1313,\n",
       " 530,\n",
       " 512,\n",
       " 1577,\n",
       " 786,\n",
       " 934,\n",
       " 248,\n",
       " 1378,\n",
       " 1184,\n",
       " 983,\n",
       " 1293,\n",
       " 902,\n",
       " 625,\n",
       " 120,\n",
       " 874,\n",
       " 42,\n",
       " 1636,\n",
       " 147,\n",
       " 19,\n",
       " 590,\n",
       " 381,\n",
       " 542,\n",
       " 12]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_sets[0].indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "client1_data = client_train_datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "client1_data.dataset.dataset.root = '/home/master24/decentralized_deep_learning/Homework3-PACS/PACS/photo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/master24/decentralized_deep_learning/Homework3-PACS/PACS/photo'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client1_data.dataset.dataset.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/edvinli/Documents/Git/Homework3-PACS/PACS/photo/elephant/064_0007.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#iterate over client1_data pytorch subset dataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(client1_data)):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mclient1_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataset.py:391\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[0;32m--> 391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataset.py:391\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[0;32m--> 391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/datasets/folder.py:229\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03m    index (int): Index\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m    tuple: (sample, target) where target is class_index of the target class.\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m path, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples[index]\n\u001b[0;32m--> 229\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(sample)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/datasets/folder.py:268\u001b[0m, in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accimage_loader(path)\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpil_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/datasets/folder.py:246\u001b[0m, in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpil_loader\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Image\u001b[38;5;241m.\u001b[39mImage:\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[39;00m\n\u001b[0;32m--> 246\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    247\u001b[0m         img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(f)\n\u001b[1;32m    248\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/edvinli/Documents/Git/Homework3-PACS/PACS/photo/elephant/064_0007.jpg'"
     ]
    }
   ],
   "source": [
    "#iterate over client1_data pytorch subset dataset\n",
    "for i in range(len(client1_data)):\n",
    "    print(client1_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#print images from client1_data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mclient1_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataset.py:391\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[0;32m--> 391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m]\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "#print images from client1_data\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(client1_data['image'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
